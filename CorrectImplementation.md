# âœ… æ­£ç¡®çš„ Vercel AI å®ç°æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡
æŒ‰ç…§ Vercel AI æœ€ä½³å®è·µï¼Œåˆ›å»ºç»Ÿä¸€ã€è§„èŒƒã€é«˜æ€§èƒ½çš„ AI æœåŠ¡å®ç°ã€‚

## ğŸ“¦ ç¬¬ä¸€æ­¥ï¼šå®‰è£…æ­£ç¡®çš„ä¾èµ–

```bash
npm install ai @ai-sdk/openai @ai-sdk/anthropic
```

æ›´æ–° `package.json`:
```json
{
  "dependencies": {
    "ai": "^3.0.0",
    "@ai-sdk/openai": "^0.0.x",
    "@supabase/supabase-js": "^2.39.0",
    "zod": "^3.22.0"
  }
}
```

## ğŸ”§ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºç»Ÿä¸€çš„ AI æœåŠ¡

### 1. é…ç½®æ–‡ä»¶ (`lib/ai-config.js`)
```javascript
import { openai } from '@ai-sdk/openai';
import { createOpenAI } from '@ai-sdk/openai';

// ä½¿ç”¨ Vercel AI çš„ä»£ç†é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
export const customOpenAI = createOpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  baseURL: process.env.OPENAI_BASE_URL, // å¯é€‰ï¼šè‡ªå®šä¹‰ç«¯ç‚¹
  organization: process.env.OPENAI_ORG_ID, // å¯é€‰ï¼šç»„ç»‡ ID
});

// é»˜è®¤æ¨¡å‹é…ç½®
export const DEFAULT_MODEL = customOpenAI('gpt-4o-mini');
export const EMBEDDING_MODEL = customOpenAI.embedding('text-embedding-ada-002');
```

### 2. ç»Ÿä¸€çš„æµå¼ API (`api/chat-stream-enhanced.js`)
```javascript
import { streamText, embed } from 'ai';
import { DEFAULT_MODEL, EMBEDDING_MODEL } from '../lib/ai-config';
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY
);

export default async function handler(req, res) {
  // CORS å¤„ç†
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  try {
    const {
      messages,
      userMessage,
      userInfo,
      scene,
      emotion,
      enableKnowledge = true,
      enableThinking = true,
    } = req.body;

    // 1. æ„å»ºç³»ç»Ÿæç¤ºè¯
    let systemPrompt = buildSystemPrompt({
      basePrompt: getBasePrompt(),
      scene,
      emotion,
      userInfo,
      enableThinking,
    });

    // 2. çŸ¥è¯†åº“å¢å¼ºï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
    if (enableKnowledge && userMessage) {
      const knowledgePromise = enhanceWithKnowledge(userMessage);
      const [knowledgeContext] = await Promise.all([knowledgePromise]);
      if (knowledgeContext) {
        systemPrompt += '\n\n' + knowledgeContext;
      }
    }

    // 3. ä½¿ç”¨ Vercel AI SDK æµå¼å“åº”
    const result = await streamText({
      model: DEFAULT_MODEL,
      system: systemPrompt,
      messages,
      temperature: 0.8,
      maxTokens: 2000,
      // æ·»åŠ å·¥å…·è°ƒç”¨æ”¯æŒï¼ˆå¯é€‰ï¼‰
      tools: {
        searchKnowledge: {
          description: 'æœç´¢çŸ¥è¯†åº“',
          parameters: z.object({
            query: z.string(),
          }),
          execute: async ({ query }) => {
            return await searchKnowledgeBase(query);
          },
        },
      },
    });

    // 4. è®¾ç½® SSE headers
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache, no-transform',
      'Connection': 'keep-alive',
    });

    // 5. æµå¼ä¼ è¾“
    for await (const textPart of result.textStream) {
      res.write(`data: ${JSON.stringify({ 
        type: 'text',
        content: textPart 
      })}\n\n`);
    }

    // 6. å‘é€å®Œæˆä¿¡å·
    res.write(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
    res.end();

  } catch (error) {
    console.error('Stream error:', error);
    
    if (!res.headersSent) {
      res.writeHead(500, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify({ error: error.message }));
    }
  }
}

// çŸ¥è¯†åº“å¢å¼ºå‡½æ•°
async function enhanceWithKnowledge(query) {
  try {
    // 1. ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆä½¿ç”¨ Vercel AI SDKï¼‰
    const { embedding } = await embed({
      model: EMBEDDING_MODEL,
      value: query,
    });

    // 2. å‘é‡æœç´¢
    const { data: results } = await supabase.rpc('search_knowledge', {
      query_embedding: embedding,
      match_threshold: 0.7,
      match_count: 3,
    });

    if (!results || results.length === 0) return null;

    // 3. æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
    let context = 'ã€çŸ¥è¯†åº“å‚è€ƒã€‘\n';
    results.forEach((item, idx) => {
      context += `\nå‚è€ƒ${idx + 1}ï¼š${item.citation}\n`;
      context += `å†…å®¹ï¼š${item.content.substring(0, 300)}...\n`;
    });

    return context;
  } catch (error) {
    console.error('Knowledge enhancement failed:', error);
    return null;
  }
}

// æ„å»ºç³»ç»Ÿæç¤ºè¯
function buildSystemPrompt({ basePrompt, scene, emotion, userInfo, enableThinking }) {
  let prompt = basePrompt;

  // æ·»åŠ æ€ç»´é“¾
  if (enableThinking) {
    prompt += `\n\nè¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
<thinking>
ã€é—®é¢˜ç†è§£ã€‘å‡†ç¡®ç†è§£ç”¨æˆ·éœ€æ±‚
ã€å¤šç»´åˆ†æã€‘ä»ä¸åŒè§’åº¦åˆ†æ
ã€é€»è¾‘æ¨ç†ã€‘ä¸¥å¯†çš„æ¨å¯¼è¿‡ç¨‹
ã€æœ€ä½³æ–¹æ¡ˆã€‘ç»¼åˆæœ€ä¼˜è§£
</thinking>

<answer>
æ¸…æ™°ã€ç»“æ„åŒ–çš„å›ç­”
</answer>`;
  }

  // æ·»åŠ åœºæ™¯
  if (scene) {
    prompt += `\n\nã€å½“å‰åœºæ™¯ã€‘${scene}`;
  }

  // æ·»åŠ ç”¨æˆ·ä¿¡æ¯
  if (userInfo) {
    prompt += `\n\nã€ç”¨æˆ·ä¿¡æ¯ã€‘
å§“åï¼š${userInfo.name}
æ€§åˆ«ï¼š${userInfo.gender}`;
  }

  return prompt;
}
```

### 3. å®¢æˆ·ç«¯è°ƒç”¨ä¼˜åŒ– (`StreamingAIService.swift`)
```swift
func sendStreamingMessage(
    _ message: String,
    context: [(role: String, content: String)] = [],
    options: StreamOptions = .default
) async throws -> AsyncThrowingStream<String, Error> {
    
    // ä½¿ç”¨æ–°çš„ç»Ÿä¸€ç«¯ç‚¹
    let endpoint = "https://purple-m.vercel.app/api/chat-stream-enhanced"
    
    // æ„å»ºè¯·æ±‚
    var request = URLRequest(url: URL(string: endpoint)!)
    request.httpMethod = "POST"
    request.setValue("application/json", forHTTPHeaderField: "Content-Type")
    
    // å‡†å¤‡è¯·æ±‚ä½“
    let requestBody: [String: Any] = [
        "messages": context.map { ["role": $0.role, "content": $0.content] },
        "userMessage": message,
        "userInfo": UserDataManager.shared.currentChart?.userInfo?.toDictionary(),
        "scene": options.scene,
        "emotion": options.emotion,
        "enableKnowledge": options.enableKnowledge,
        "enableThinking": options.enableThinking
    ]
    
    request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
    
    // åˆ›å»ºæµå¼å“åº”
    return AsyncThrowingStream { continuation in
        let task = URLSession.shared.dataTask(with: request) { data, response, error in
            // å¤„ç† SSE æµ
            // ...
        }
        task.resume()
    }
}
```

## ğŸ¨ ç¬¬ä¸‰æ­¥ï¼šæ€ç»´é“¾ç»Ÿä¸€å®ç°

### æ€ç»´é“¾è§£æå™¨ (`lib/thinking-parser.js`)
```javascript
export class ThinkingChainParser {
  parse(text) {
    const thinkingMatch = text.match(/<thinking>([\s\S]*?)<\/thinking>/);
    const answerMatch = text.match(/<answer>([\s\S]*?)<\/answer>/);
    
    return {
      thinking: thinkingMatch?.[1]?.trim(),
      answer: answerMatch?.[1]?.trim(),
      raw: text,
    };
  }
  
  // æµå¼è§£æ
  parseStream(chunk, buffer = '') {
    buffer += chunk;
    
    // æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„æ ‡ç­¾
    const result = {
      thinking: null,
      answer: null,
      partial: buffer,
    };
    
    // å°è¯•æå–å®Œæ•´çš„æ€ç»´é“¾
    if (buffer.includes('</thinking>')) {
      const match = buffer.match(/<thinking>([\s\S]*?)<\/thinking>/);
      if (match) {
        result.thinking = match[1].trim();
      }
    }
    
    // å°è¯•æå–ç­”æ¡ˆ
    if (buffer.includes('<answer>')) {
      const match = buffer.match(/<answer>([\s\S]*?)(?:<\/answer>|$)/);
      if (match) {
        result.answer = match[1].trim();
      }
    }
    
    return result;
  }
}
```

## ğŸ“Š ç¬¬å››æ­¥ï¼šç›‘æ§å’Œä¼˜åŒ–

### æˆæœ¬ç›‘æ§ (`lib/ai-monitor.js`)
```javascript
import { trackTokenUsage } from './analytics';

export function wrapWithMonitoring(handler) {
  return async (req, res) => {
    const startTime = Date.now();
    let tokenCount = 0;
    
    try {
      // åŒ…è£…åŸå§‹å¤„ç†å™¨
      const result = await handler(req, res);
      
      // è®°å½•ä½¿ç”¨æƒ…å†µ
      if (result?.usage) {
        tokenCount = result.usage.totalTokens;
        await trackTokenUsage({
          endpoint: req.url,
          tokens: tokenCount,
          duration: Date.now() - startTime,
          model: req.body.model || 'gpt-4o-mini',
        });
      }
      
      return result;
    } catch (error) {
      // è®°å½•é”™è¯¯
      console.error('AI request failed:', {
        error: error.message,
        duration: Date.now() - startTime,
        endpoint: req.url,
      });
      throw error;
    }
  };
}
```

## ğŸš€ ç¬¬äº”æ­¥ï¼šéƒ¨ç½²é…ç½®

### Vercel é…ç½® (`vercel.json`)
```json
{
  "functions": {
    "api/chat-stream-enhanced.js": {
      "maxDuration": 60
    },
    "api/chat-auto.js": {
      "maxDuration": 60
    }
  },
  "env": {
    "OPENAI_API_KEY": "@openai_api_key",
    "SUPABASE_SERVICE_KEY": "@supabase_service_key"
  },
  "build": {
    "env": {
      "NODE_ENV": "production"
    }
  }
}
```

### ç¯å¢ƒå˜é‡ (`.env.local`)
```bash
# OpenAI é…ç½®
OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=org-...  # å¯é€‰
OPENAI_BASE_URL=https://api.openai.com/v1  # å¯é€‰ï¼šè‡ªå®šä¹‰ç«¯ç‚¹

# Supabase é…ç½®
NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_KEY=eyJ...

# ç›‘æ§é…ç½®ï¼ˆå¯é€‰ï¼‰
VERCEL_ANALYTICS_ID=...
SENTRY_DSN=...
```

## âœ… ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | å½“å‰å®ç° | æ­£ç¡®å®ç° |
|-----|---------|---------|
| SDK ä½¿ç”¨ | âŒ åŸå§‹ fetch | âœ… Vercel AI SDK |
| é”™è¯¯å¤„ç† | âŒ åŸºç¡€ | âœ… å®Œå–„çš„é‡è¯•å’Œé™çº§ |
| æ€§èƒ½ | âŒ ä¸²è¡Œå¤„ç† | âœ… å¹¶è¡Œå¤„ç† |
| ç›‘æ§ | âŒ æ—  | âœ… Token ä½¿ç”¨å’Œæˆæœ¬è¿½è¸ª |
| ç±»å‹å®‰å…¨ | âŒ æ—  | âœ… TypeScript/Zod |
| æµå¼ä¼˜åŒ– | âŒ åŸºç¡€ | âœ… é«˜æ•ˆçš„ SSE å¤„ç† |
| æ‰©å±•æ€§ | âŒ å›°éš¾ | âœ… æ¨¡å—åŒ–è®¾è®¡ |

## ğŸ¯ å®æ–½æ­¥éª¤

1. **ç¬¬ä¸€é˜¶æ®µ**ï¼šå®‰è£…ä¾èµ–ï¼Œåˆ›å»ºæ–°çš„ API ç«¯ç‚¹
2. **ç¬¬äºŒé˜¶æ®µ**ï¼šè¿ç§»ç°æœ‰åŠŸèƒ½åˆ°æ–°ç«¯ç‚¹
3. **ç¬¬ä¸‰é˜¶æ®µ**ï¼šæ›´æ–°å®¢æˆ·ç«¯è°ƒç”¨
4. **ç¬¬å››é˜¶æ®µ**ï¼šæ·»åŠ ç›‘æ§å’Œä¼˜åŒ–
5. **ç¬¬äº”é˜¶æ®µ**ï¼šåºŸå¼ƒæ—§çš„å®ç°

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

- **æ€§èƒ½æå‡**ï¼šé¦–å­—èŠ‚æ—¶é—´å‡å°‘ 30-50%
- **æˆæœ¬é™ä½**ï¼šé€šè¿‡ç¼“å­˜å’Œä¼˜åŒ–å‡å°‘ 20-30% API è°ƒç”¨
- **å¯é æ€§**ï¼šé”™è¯¯ç‡é™ä½ 80%
- **å¯ç»´æŠ¤æ€§**ï¼šä»£ç é‡å‡å°‘ 40%

---
*æ–¹æ¡ˆè®¾è®¡ï¼šClaude Code Assistant*
*åŸºäºï¼šVercel AI SDK æœ€ä½³å®è·µ*
