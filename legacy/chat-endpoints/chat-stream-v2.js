// Vercel API - ç»Ÿä¸€çš„æµå¼å¯¹è¯æ¥å£ v2
// ä½¿ç”¨ Vercel AI Gateway å®ç°æ ‡å‡†åŒ–çš„æµå¼å“åº”

import { streamChatCompletion, generateEmbedding, handleStreamResponse } from '../lib/ai-gateway-client.js';
import { TEMPERATURE, TOKEN_LIMITS, SYSTEM_PROMPTS, SCENE_CONFIGS } from '../lib/ai-config.js';
import { createClient } from '@supabase/supabase-js';

// ä½¿ç”¨ Node.js è¿è¡Œæ—¶ä»¥æ”¯æŒæ‰€æœ‰åŠŸèƒ½
export const runtime = 'nodejs';
export const maxDuration = 60;

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
);

export default async function handler(req, res) {
  // CORS å¤„ç†
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
  
  if (req.method === 'OPTIONS') {
    return res.status(200).end();
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const {
      messages = [],
      userMessage,
      userInfo,
      scene,
      emotion,
      chartContext,
      enableKnowledge = true,
      enableThinking = true,
      model = 'standard',
      temperature,
    } = req.body;

    console.log('ğŸ“ Stream v2 request:', {
      hasUserMessage: !!userMessage,
      hasUserInfo: !!userInfo,
      scene,
      emotion,
      enableKnowledge,
      enableThinking,
      model,
      messageCount: messages.length
    });

    // 1. æ„å»ºç³»ç»Ÿæç¤ºè¯
    let systemPrompt = buildSystemPrompt({
      basePrompt: SYSTEM_PROMPTS.base,
      scene,
      emotion,
      userInfo,
      chartContext,
      enableThinking,
    });

    // 2. çŸ¥è¯†åº“å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if (enableKnowledge && userMessage) {
      try {
        const knowledgeContext = await enhanceWithKnowledge(userMessage);
        if (knowledgeContext) {
          systemPrompt += '\n\n' + knowledgeContext;
          console.log('âœ… Knowledge enhanced with', knowledgeContext.length, 'chars');
        }
      } catch (error) {
        console.error('âŒ Knowledge enhancement failed:', error);
        // ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹
      }
    }

    // 3. é€‰æ‹©æ¨¡å‹
    const modelMap = {
      'fast': 'openai/gpt-5',        // å¿«é€Ÿæ¨¡å¼ä½¿ç”¨GPT-5
      'standard': 'openai/gpt-5',    // æ ‡å‡†æ¨¡å¼ä½¿ç”¨GPT-5
      'advanced': 'openai/gpt-5',    // é«˜çº§æ¨¡å¼ä½¿ç”¨GPT-5
    };
    const selectedModel = modelMap[model] || 'openai/gpt-5';  // é»˜è®¤ GPT-5
    
    // 4. è·å–åœºæ™¯é…ç½®
    const sceneConfig = scene ? SCENE_CONFIGS[scene] : {};
    const finalTemperature = temperature ?? sceneConfig.temperature ?? TEMPERATURE.balanced;
    const maxTokens = sceneConfig.maxTokens || TOKEN_LIMITS.large;

    // 5. æ„å»ºå®Œæ•´çš„æ¶ˆæ¯æ•°ç»„
    const allMessages = [
      { role: 'system', content: systemPrompt },
      ...messages
    ];

    // 6. ä½¿ç”¨ Vercel AI Gateway åˆ›å»ºæµå¼å“åº”
    const response = await streamChatCompletion({
      messages: allMessages,
      model: selectedModel,
      temperature: finalTemperature,
      maxTokens: maxTokens,
      stream: true,
    });

    // 7. è®¾ç½® SSE headers
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache, no-transform',
      'Connection': 'keep-alive',
      'X-Accel-Buffering': 'no', // ç¦ç”¨ Nginx ç¼“å†²
    });

    // 8. æµå¼ä¼ è¾“å“åº”
    let fullResponse = '';
    let chunkCount = 0;
    
    for await (const textPart of handleStreamResponse(response)) {
      if (textPart) {
        fullResponse += textPart;
        chunkCount++;
        
        // å‘é€æ•°æ®å—
        const data = JSON.stringify({ 
          type: 'text',
          content: textPart,
          chunkIndex: chunkCount,
        });
        res.write(`data: ${data}\n\n`);
        
        // å®šæœŸåˆ·æ–°ä»¥ç¡®ä¿å®¢æˆ·ç«¯æ¥æ”¶
        if (chunkCount % 5 === 0) {
          res.flush?.();
        }
      }
    }
    
    // 9. å‘é€å®Œæˆä¿¡å·
    res.write(`data: ${JSON.stringify({ 
      type: 'done',
      totalChunks: chunkCount,
      totalLength: fullResponse.length,
    })}\n\n`);
    
    res.end();
    
    console.log('âœ… Stream completed:', {
      chunks: chunkCount,
      length: fullResponse.length,
      tokens: usage?.totalTokens,
    });

  } catch (error) {
    console.error('âŒ Stream v2 error:', error);
    
    // å¦‚æœè¿˜æ²¡æœ‰å‘é€å“åº”å¤´ï¼Œè¿”å› JSON é”™è¯¯
    if (!res.headersSent) {
      const statusCode = error.message?.includes('API key') ? 401 :
                        error.message?.includes('rate limit') ? 429 : 500;
      
      return res.status(statusCode).json({ 
        error: error.message || 'Internal server error',
        type: 'stream_error',
        details: process.env.NODE_ENV === 'development' ? error.stack : undefined,
      });
    }
    
    // å¦‚æœå·²ç»åœ¨æµå¼ä¼ è¾“ä¸­ï¼Œå‘é€é”™è¯¯äº‹ä»¶
    res.write(`data: ${JSON.stringify({ 
      type: 'error',
      error: error.message 
    })}\n\n`);
    res.end();
  }
}

// çŸ¥è¯†åº“å¢å¼ºå‡½æ•°
async function enhanceWithKnowledge(query) {
  try {
    // 1. ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆä½¿ç”¨ Vercel AI Gatewayï¼‰
    const embedding = await generateEmbedding(query);

    // 2. å‘é‡æœç´¢
    const { data: results, error } = await supabase.rpc('search_knowledge', {
      query_embedding: embedding,
      match_threshold: 0.7,
      match_count: 3,
    });

    if (error) {
      console.error('Supabase search error:', error);
      return null;
    }

    if (!results || results.length === 0) {
      console.log('No knowledge results found');
      return null;
    }

    // 3. æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
    let context = 'ã€çŸ¥è¯†åº“å‚è€ƒã€‘\n';
    results.forEach((item, idx) => {
      context += `\nå‚è€ƒ${idx + 1}ï¼š`;
      if (item.citation) {
        context += `${item.citation}\n`;
      }
      if (item.content) {
        // é™åˆ¶æ¯æ¡å†…å®¹é•¿åº¦
        const content = item.content.substring(0, 300);
        context += `å†…å®¹ï¼š${content}${item.content.length > 300 ? '...' : ''}\n`;
      }
      context += `ç›¸å…³åº¦ï¼š${(item.similarity * 100).toFixed(1)}%\n`;
    });

    return context;
  } catch (error) {
    console.error('Knowledge enhancement failed:', error);
    return null;
  }
}

// æ„å»ºç³»ç»Ÿæç¤ºè¯
function buildSystemPrompt({ 
  basePrompt, 
  scene, 
  emotion, 
  userInfo, 
  chartContext,
  enableThinking 
}) {
  let prompt = basePrompt;

  // æ·»åŠ æ€ç»´é“¾æ¨¡å¼
  if (enableThinking) {
    prompt += SYSTEM_PROMPTS.thinking;
  }

  // æ·»åŠ åœºæ™¯ä¸Šä¸‹æ–‡
  if (scene && SCENE_CONFIGS[scene]) {
    prompt += `\n\nã€å½“å‰åœºæ™¯ã€‘${scene}\n${SCENE_CONFIGS[scene].prompt}`;
  }

  // æ·»åŠ æƒ…ç»ªè¯†åˆ«
  if (emotion) {
    const emotionGuide = {
      'anxious': 'ç”¨æˆ·ä¼¼ä¹æœ‰äº›ç„¦è™‘ï¼Œè¯·ç»™äºˆå®‰æŠšå’Œæ”¯æŒ',
      'curious': 'ç”¨æˆ·å……æ»¡å¥½å¥‡å¿ƒï¼Œå¯ä»¥æ·±å…¥è®²è§£',
      'confused': 'ç”¨æˆ·å¯èƒ½æœ‰å›°æƒ‘ï¼Œè¯·è€å¿ƒè§£é‡Š',
      'excited': 'ç”¨æˆ·å¾ˆå…´å¥‹ï¼Œå¯ä»¥åˆ†äº«ä»–ä»¬çš„å–œæ‚¦',
      'worried': 'ç”¨æˆ·æœ‰æ‹…å¿§ï¼Œè¯·ç»™äºˆç†è§£å’Œå»ºè®®',
    };
    
    if (emotionGuide[emotion]) {
      prompt += `\n\nã€æƒ…ç»ªæ„ŸçŸ¥ã€‘${emotionGuide[emotion]}`;
    }
  }

  // æ·»åŠ ç”¨æˆ·ä¿¡æ¯
  if (userInfo) {
    prompt += `\n\nã€ç”¨æˆ·ä¿¡æ¯ã€‘`;
    if (userInfo.name) prompt += `\nå§“åï¼š${userInfo.name}`;
    if (userInfo.gender) prompt += `\næ€§åˆ«ï¼š${userInfo.gender}`;
    if (userInfo.birthDate) prompt += `\nç”Ÿæ—¥ï¼š${userInfo.birthDate}`;
    if (userInfo.birthTime) prompt += `\nå‡ºç”Ÿæ—¶é—´ï¼š${userInfo.birthTime}`;
    if (userInfo.birthPlace) prompt += `\nå‡ºç”Ÿåœ°ï¼š${userInfo.birthPlace}`;
  }

  // æ·»åŠ å‘½ç›˜ä¸Šä¸‹æ–‡
  if (chartContext) {
    prompt += `\n\nã€å‘½ç›˜ä¿¡æ¯ã€‘\n${chartContext}`;
  }

  return prompt;
}

// å¯¼å‡ºå·¥å…·å‡½æ•°ä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
export { enhanceWithKnowledge, buildSystemPrompt };