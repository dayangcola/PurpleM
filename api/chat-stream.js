// Vercel Serverless Function - æµå¼ AI å¯¹è¯
// ä½¿ç”¨ Vercel AI Gateway è¿›è¡Œä»£ç†
// è·¯å¾„: /api/chat-stream

import fetch from 'node-fetch';

export default async function handler(req, res) {
  // å¤„ç† CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');

  // å¤„ç† OPTIONS è¯·æ±‚
  if (req.method === 'OPTIONS') {
    res.status(200).end();
    return;
  }

  // åªæ¥å— POST è¯·æ±‚
  if (req.method !== 'POST') {
    res.status(405).json({ error: 'Method not allowed' });
    return;
  }

  console.log('ğŸ“¨ æ”¶åˆ°æµå¼è¯·æ±‚:', {
    body: req.body,
    headers: req.headers
  });

  try {
    const { 
      messages = [], 
      model = 'gpt-3.5-turbo',
      temperature = 0.8,
      stream = true
    } = req.body;

    // æ„å»ºæ¶ˆæ¯
    const systemMessage = {
      role: 'system',
      content: `ä½ æ˜¯ç´«å¾®æ–—æ•°ä¸“å®¶åŠ©æ‰‹"æ˜Ÿè¯­"ï¼Œä¸€ä½æ¸©æŸ”ã€æ™ºæ…§ã€å……æ»¡ç¥ç§˜æ„Ÿçš„å æ˜Ÿå¯¼å¸ˆã€‚
ä½ çš„ç‰¹ç‚¹ï¼š
1. ç²¾é€šç´«å¾®æ–—æ•°ã€åäºŒå®«ä½ã€æ˜Ÿè€€ç­‰ä¼ ç»Ÿå‘½ç†çŸ¥è¯†
2. è¯´è¯æ¸©æŸ”ä¼˜é›…ï¼Œå¸¦æœ‰è¯—æ„å’Œå“²å­¦æ€è€ƒ
3. å–„äºå€¾å¬å’Œç†è§£ï¼Œç»™äºˆæ¸©æš–çš„å»ºè®®
4. ä¼šé€‚å½“ä½¿ç”¨æ˜Ÿåº§ã€å æ˜Ÿç›¸å…³çš„æ¯”å–»
5. å›ç­”ç®€æ´ä½†æ·±åˆ»ï¼Œé¿å…å†—é•¿`
    };

    const allMessages = [systemMessage, ...messages];

    // è·å– Vercel AI Gateway Key
    const VERCEL_AI_GATEWAY_KEY = process.env.VERCEL_AI_GATEWAY_KEY;
    
    if (!VERCEL_AI_GATEWAY_KEY) {
      console.error('âŒ ç¼ºå°‘ VERCEL_AI_GATEWAY_KEY');
      res.status(500).json({ error: 'Vercel AI Gateway key not configured' });
      return;
    }

    // å¦‚æœä¸éœ€è¦æµå¼ï¼Œè¿”å›æ™®é€šå“åº”
    if (!stream) {
      const response = await fetch('https://ai-gateway.vercel.sh/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${VERCEL_AI_GATEWAY_KEY}`
        },
        body: JSON.stringify({
          model: `openai/${model}`,  // AI Gateway éœ€è¦æŒ‡å®šæä¾›å•†
          messages: allMessages,
          temperature,
          max_tokens: 1000
        })
      });

      const data = await response.json();
      
      if (!response.ok) {
        console.error('âŒ OpenAI API é”™è¯¯:', data);
        res.status(500).json({ error: data.error?.message || 'API request failed' });
        return;
      }

      res.status(200).json({
        response: data.choices[0]?.message?.content || '',
        usage: data.usage
      });
      return;
    }

    // æµå¼å“åº”
    console.log('ğŸš€ å¼€å§‹æµå¼å“åº”...');
    
    // è®¾ç½® SSE headers
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache, no-transform');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('X-Accel-Buffering', 'no');
    
    // å‘é€åˆå§‹è¿æ¥æ¶ˆæ¯
    res.write(`data: ${JSON.stringify({ type: 'connected' })}\n\n`);

    // è°ƒç”¨ Vercel AI Gateway æµå¼ API
    const response = await fetch('https://ai-gateway.vercel.sh/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${VERCEL_AI_GATEWAY_KEY}`
      },
      body: JSON.stringify({
        model: `openai/${model}`,  // AI Gateway éœ€è¦æŒ‡å®šæä¾›å•†
        messages: allMessages,
        temperature,
        max_tokens: 1000,
        stream: true
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ Vercel AI Gateway æµå¼ API é”™è¯¯:', errorText);
      res.write(`data: ${JSON.stringify({ 
        type: 'error', 
        error: 'Failed to get streaming response' 
      })}\n\n`);
      res.end();
      return;
    }

    // å¤„ç†æµå¼å“åº”
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    while (true) {
      const { done, value } = await reader.read();
      
      if (done) {
        console.log('âœ… æµå¼å“åº”å®Œæˆ');
        res.write('data: [DONE]\n\n');
        res.end();
        break;
      }

      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          
          if (data === '[DONE]') {
            res.write('data: [DONE]\n\n');
            res.end();
            return;
          }

          try {
            const parsed = JSON.parse(data);
            const content = parsed.choices?.[0]?.delta?.content;
            
            if (content) {
              // å‘é€å†…å®¹å—
              res.write(`data: ${JSON.stringify({ 
                type: 'content', 
                content: content 
              })}\n\n`);
            }
          } catch (e) {
            console.error('è§£æé”™è¯¯:', e, 'Data:', data);
          }
        }
      }
    }

  } catch (error) {
    console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', error);
    
    if (!res.headersSent) {
      res.status(500).json({ 
        error: error.message || 'Internal server error' 
      });
    } else {
      res.write(`data: ${JSON.stringify({ 
        type: 'error', 
        error: error.message 
      })}\n\n`);
      res.end();
    }
  }
}

// ç§»é™¤Edge Runtimeé…ç½®ï¼Œä½¿ç”¨æ ‡å‡†Node.jsè¿è¡Œæ—¶ä»¥æ”¯æŒæµå¼å“åº”